# Supervised machine learning algorithms - Classification

The repository contains files:

- LogisticRegressionNew.py - Logistic Regression to predict customer churn
- Decision_trees.py - using Decision Tree as a multiclass predictor on which drug might be the most appropriate for a future patient
- Decission_Tre_vs_SVM_card_fraud.py - comparing Support Vector Machine to Decision Tree efficiency in credit card fraud detection
- KNN_Classificator_Telecom_CustSegments.py - using KNN to classify Telecom company customers
- Evaluation_of_binary_classificators.py - evaluation metrics for binary classifiers
- RAIN_PREDICTION_Final_project.py (Pipelines Folder) - use of Pipelines and Grid Search to predict the possibility of rain in Australia
- RAIN_PREDICTION_Final_project_cities_clustering.py - HDBSCAN clustering of cities based on longitude and latitude
- Pipelines_Feature_importances_Titanic.py (Pipelines Folder) -use of Pipelines and Grid Search to predict the survival rate of passangers on Titanic

Dataset Sources: 

  - ChurnData.cvs - historical customer dataset
  - drug200.cvs - dataset provided by IBM Developer Skills Network
  - Kaggle Dataset available at https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud
  - teleCust1000t - dataset provided by IBM Developer Skills Network
  - the copy of UCI ML Breast Cancer Wisconsin (Diagnostic) dataset available to load from sklearn or from the following link:https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic
  - Kaggle Dataset available at https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package/ and AUCities.csv
  - Seaborn Dataset available at https://github.com/kailasdumane/seaborn-datasets/blob/master/titanic.csv

Technologies Used: python, pandas, matplotlib, scikit-learn, plotly, seaborn

Installation: copy and run the code in Jupyter Notebooks or other Python editor of choice. Keep dataset files in the same folder.

![Feature_Importances_in_Random_Forest_Regression](https://raw.githubusercontent.com/natvnu/Machine_Learning/0e4932d49f493e5f633fd70bb80ccc3c65409168/Supervised%20Machine%20Learning%20-%20Regression/3_Feature_Importances_in_Random_Forest_Regression.png)

![Regularization_Linear_regression_coefficients](https://raw.githubusercontent.com/natvnu/Machine_Learning/0e4932d49f493e5f633fd70bb80ccc3c65409168/Supervised%20Machine%20Learning%20-%20Regression/4_Regularization_Linear_regression_coefficients.png)

![Regularization_Linear_regression_linear_ridge_lasso_vs_ideal](https://raw.githubusercontent.com/natvnu/Machine_Learning/0e4932d49f493e5f633fd70bb80ccc3c65409168/Supervised%20Machine%20Learning%20-%20Regression/4_Regularization_Linear_regression_linear_ridge_lasso_vs_ideal.png)

![Random_Forest_Predictions_vs_Actual_and_Xboost_prediction_vs_actual](https://raw.githubusercontent.com/natvnu/Machine_Learning/0e4932d49f493e5f633fd70bb80ccc3c65409168/Supervised%20Machine%20Learning%20-%20Regression/Random_Forest_Predictions_vs_Actual_and_Xboost_prediction_vs_actual.png)

![Regularization_Linear_regression_linear_ridge_lasso_vs_ideal](https://raw.githubusercontent.com/natvnu/Machine_Learning/0e4932d49f493e5f633fd70bb80ccc3c65409168/Supervised%20Machine%20Learning%20-%20Regression/4_Regularization_Linear_regression_linear_ridge_lasso_vs_ideal.png)

![Random_Forest_Predictions_vs_Actual_and_Xboost_prediction_vs_actual](https://raw.githubusercontent.com/natvnu/Machine_Learning/0e4932d49f493e5f633fd70bb80ccc3c65409168/Supervised%20Machine%20Learning%20-%20Regression/Random_Forest_Predictions_vs_Actual_and_Xboost_prediction_vs_actual.png)





